---
title: "Student Dropout Prediction Challenge: Data wrangling to Feature Engineering"
author: "Hamed"
date: "3/24/2020"
output: word_document
---

This R markdown document contains well commented code and output of the whole process of machine learning from Data wrangling to Modelling.


# DATA WRANGLING

#### Financial aid data loading

```{r,warning=FALSE}
financial_aid<-read.csv("financial_aid.csv",header = T)
summary(financial_aid)

```

- The data loaded has periodic capture financial information whereby variables; loan, workstudy, grant and scholarship are recorded multiple times.
- Therefore to get independent variables out of these variables; Combine by summing the loan, scholarship, grant and work/study data from 2011 to 2017 as follows;

```{r,warning=FALSE}

library(tidyverse)
attach(financial_aid)
financial_aid=financial_aid %>%
  mutate(Total_loan = select(.,c(X2012.Loan,X2013.Loan,X2014.Loan,
           X2015.Loan,X2016.Loan,X2017.Loan)) %>%
           rowSums(na.rm = TRUE))

financial_aid<-financial_aid%>%
  mutate(Total_grant=select(.,c(X2012.Grant,X2013.Grant,X2014.Grant,
          X2015.Grant,X2016.Grant,X2017.Grant))%>%
           rowSums(na.rm = TRUE))

financial_aid<-financial_aid%>%
  mutate(Total_scholarship=select(.,c(X2012.Scholarship,X2013.Scholarship,X2014.Scholarship,
            X2015.Scholarship,X2016.Scholarship,X2017.Scholarship))%>%
           rowSums(na.rm = TRUE))

financial_aid<-financial_aid%>%
  mutate(Total_WorkStudy=select(.,c(X2012.Work.Study,X2013.Work.Study,
    X2014.Work.Study,X2015.Work.Study,X2016.Work.Study,X2017.Work.Study))%>%
           rowSums(na.rm = TRUE))

# Variables 
colnames(financial_aid)

```


Data cleaning : drop the periodic columns after creating the independent variables in order to have relevant columns only.

```{r,warning=FALSE}
# drop the extra periodical financial data 
financial_aid<-financial_aid[,-c(9:32)]

# Load the train labels and the TestIDs
train_labels=read.csv("DropoutTrainLabels.csv",header = T)
testIDs=read.csv("TestIDs.csv",header = T)

```


JOIN the train labels and the financial aid data

```{r,warning=FALSE}
library(dplyr)
financial_aid_train=left_join(train_labels,financial_aid,by="StudentID")
dim(financial_aid_train)
# JOIN the test IDs and the financial aid data
financial_aid_test=left_join(testIDs,financial_aid,by="StudentID")
dim(financial_aid_test)

```


Check for duplicated StudentID (TRUE=No duplicates, FALSE=duplicates present)

```{r,warning=FALSE}

length(unique(financial_aid_train$StudentID)) == nrow(financial_aid_train)

```


### STATIC Data

STATIC data files loaded and merged using a function that iterates through a folder and picks up all files loads and merges them into one data frame. 

```{r,warning=FALSE}
#load all files and merge them
myETL=function(mypath){
  filenames = list.files(path=mypath, full.names=TRUE)
  file_load = function(x){read.csv(file=x,header=T)}
  datalist = lapply(filenames, file_load)
  data2 = do.call(rbind, lapply(datalist, as.data.frame))
  return(data2)
}
# call the function
mergedStatic<-myETL("D:/Hamed/KAGGLE COMPETITION/Student Retention Challenge Data/Student Static Data")

# Variable names in static dataset
colnames(mergedStatic)

```


Check for duplicated StudentID (TRUE=No duplicates, FALSE=duplicates present)
```{r,warning=FALSE}
length(unique(mergedStatic$StudentID)) == nrow(mergedStatic)

```

Since there were no duplicated student IDs, JOIN the train labels & test IDs and the static data

```{r,warning=FALSE}
library(dplyr)
static_train=left_join(train_labels,mergedStatic,by="StudentID")
summary(static_train)

# JOIN the test IDs and the static data
static_test=left_join(testIDs,mergedStatic,by="StudentID")

```



### PROGRESS Data

Loaded and merged using a function that iterates through a folder and picks up all files loads and merges them into one data frame. 

```{r,warning=FALSE}

myETL=function(mypath){
filenames = list.files(path=mypath, full.names=TRUE)
file_load = function(x){read.csv(file=x,header=T)}
datalist = lapply(filenames, file_load)
data2 = do.call(rbind, lapply(datalist, as.data.frame))
return(data2)
}

# call the function
mergedProgress<-myETL("D:/Hamed/KAGGLE COMPETITION/Student Retention Challenge Data/Student Progress Data")

# variable names in the progress data
colnames(mergedProgress)
dim(mergedProgress)
```


Check for duplicated StudentID (TRUE=No duplicates, FALSE=duplicates present)
```{r,warning=FALSE}

length(unique(mergedProgress$StudentID)) == nrow(mergedProgress)


```

- The data had alot of duplicated student IDs thus to get only unique student ID the data frame was summarised and grouped by student ID.
- Thereafter a left join with the train labels to capter the students appearing only in the train labels data frame. 

```{r,warning=FALSE}
library(plyr)
prog1=ddply(mergedProgress,.(StudentID),summarize,
            CompleteDevMath=mean(CompleteDevMath),CompleteDevEnglish=mean(CompleteDevEnglish),
            Major1=mean(Major1),Major2=mean(Major2),Complete1=mean(Complete1),
            Complete2=mean(Complete2),CompleteCIP1=mean(CompleteCIP1),
            CompleteCIP2=mean(CompleteCIP2),TransferIntent=mean(TransferIntent),
            DegreeTypeSought=mean(DegreeTypeSought),TermGPA=mean(CumGPA),
            CumGPA=mean(CumGPA),number=length(StudentID))
dim(prog1)

# drop the irrelevant frequency column
prog1<-prog1[,-14]
dim(prog1)


# JOIN the train labels and the progress data
library(dplyr)
progress_train=left_join(train_labels,prog1,by="StudentID")
# JOIN the test IDs and the progress data
progress_test=left_join(testIDs,prog1,by="StudentID")

dim(progress_train)

# variables names for the progress data
summary(progress_train)

```

Check to ensure that all the datasets are of the same row and column sizes before merging them

```{r}

dim(financial_aid_train)
dim(financial_aid_test)

dim(static_train)
dim(static_test)

dim(progress_train)
dim(progress_test)

```



### TRAINING DATASET
- The train data set was created by use of a inner join function between financial , static and progress. The same was done for test data.  

- The data was cleaned by removing irrelevant(duplicated) columns and and renaming the Dropout variable. 
- The missing values were clearly assigned NA's to make sure all of them are identified.
- The categorical variables with wrong data types were corrected and assigned factor data types. 
```{r}

library(dplyr)
join1<-inner_join(financial_aid_train,static_train,by="StudentID")
TRAIN_DATA=inner_join(join1,progress_train,by="StudentID")
colnames(TRAIN_DATA)

dim(TRAIN_DATA)

# TESTING DATASET
join2<-inner_join(financial_aid_test,static_test,by="StudentID")
TEST_DATA<-inner_join(join2,progress_test,by="StudentID")
dim(TEST_DATA)


# Clean the train data by removing extra dropout variables (Dropout.y,Dropout)
TRAIN_DATA<-select(TRAIN_DATA,-c("Dropout.y"))
TRAIN_DATA<-select(TRAIN_DATA,-c("Dropout"))

# Rename the droput.x to just dropout for consistency
library(dplyr)
colnames(TRAIN_DATA)[colnames(TRAIN_DATA)=="Dropout.x"] <- "Dropout"

dim(TRAIN_DATA)
dim(TEST_DATA)

# The response variable
TRAIN_DATA$Dropout[1:5]

# The features of our project that will be analysed further
colnames(TEST_DATA)

```


```{r,warning=FALSE}
# Convert empty spaces and (-1) to NULL in order to facilitate imputation later on
TRAIN_DATA[TRAIN_DATA=="-1"]<-NA
TRAIN_DATA[TRAIN_DATA==""]<-NA


# Convert the theorically categorical variables to  factors 
names=c('DegreeTypeSought','TransferIntent','CompleteDevEnglish','CompleteDevMath',
  'GatewayEnglishStatus','GatewayMathStatus','EngPlacement','MathPlacement',
  'HighDeg','EnrollmentStatus','FirstGen','HSDip','BirthMonth','BirthYear',
  'Gender','Campus','CohortTerm','cohort_term','Dropout')

TRAIN_DATA[,names] <- lapply(TRAIN_DATA[,names] , factor)
str(TRAIN_DATA)

```


# EXPLORATORY DATA ANALYSIS


We use ggplot for our boxplots, bar plots, scatter plots to display insightful analysis
```{r}
library(ggplot2)
# Summarize the data
summary(TRAIN_DATA)

# Visualize the financial information in relation to the dropout variable whereby we look at the distribution (mean, outliers and spread) of each variable grouped by the dropout variable

library(dplyr)
ggplot(data = TRAIN_DATA, mapping = aes(x =Dropout,y=Total_loan))+
  ggtitle("Total_loan in grouped by dropout") +
  geom_boxplot()

ggplot(data = TRAIN_DATA, mapping = aes(x =Dropout,y=Total_grant))+
  ggtitle("Total_grant grouped by dropout") +
  geom_boxplot()

ggplot(data = TRAIN_DATA, mapping = aes(x =Dropout,y=Total_scholarship))+
  ggtitle("Total_scholarship grouped by dropout") +
  geom_boxplot()

ggplot(data = TRAIN_DATA, mapping = aes(x =Dropout,y=Total_WorkStudy))+
ggtitle("Total_WorkStudy grouped by dropout") +
    geom_boxplot()

```

Visualize the student performance information in relation to the dropout variable whereby we look at the distribution (mean, outliers and spread) of each variable grouped by the dropout variable

```{r}

ggplot(data = TRAIN_DATA, mapping = aes(x =Dropout,y=TermGPA))+
  ggtitle("TermGPA grouped by dropout") +
  geom_boxplot()

ggplot(data = TRAIN_DATA, mapping = aes(x =Dropout,y=CumGPA))+
  ggtitle("Total_scholarship grouped by dropout") +
  geom_boxplot()

```



Frequency analysis for categorical variables in relation to the Dropout variable

```{r}
# Dropout summary statistics
table(TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
  ggtitle("Student Dropout") +
  geom_bar(mapping = aes(x = Dropout,fill='blue'))
```


```{r}
# Marital.Status
table(TRAIN_DATA$Marital.Status,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
  ggtitle("Marital.Status grouped by dropout")+
  geom_bar(mapping = aes(x = Marital.Status,fill=Dropout))
```


```{r}
# Father.s.Highest.Grade.Level
table(TRAIN_DATA$Father.s.Highest.Grade.Level,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
  ggtitle("Father.s.Highest.Grade.Level grouped by dropout")+
    geom_bar(mapping = aes(x = Father.s.Highest.Grade.Level,fill=Dropout))
```


```{r}
# Mother.s.Highest.Grade.Level
table(TRAIN_DATA$Mother.s.Highest.Grade.Level,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
  ggtitle("Mother.s.Highest.Grade.Level grouped by dropout")+
  geom_bar(mapping = aes(x = Mother.s.Highest.Grade.Level,fill=Dropout))
```


```{r}
# Housing
table(TRAIN_DATA$Housing,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
 ggtitle("Housing grouped by dropout")+
    geom_bar(mapping = aes(x = Housing,fill=Dropout))
```


```{r}
# Cohort
table(TRAIN_DATA$Cohort,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
 ggtitle("Cohort grouped by dropout")+
   geom_bar(mapping = aes(x = Cohort,fill=Dropout))

# CohortTerm
table(TRAIN_DATA$CohortTerm,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("CohortTerm grouped by dropout")+
    geom_bar(mapping = aes(x = CohortTerm,fill=Dropout))

# MathPlacement
table(TRAIN_DATA$MathPlacement,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("MathPlacement grouped by dropout")+
    geom_bar(mapping = aes(x = MathPlacement,fill=Dropout))


# State
table(TRAIN_DATA$State,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("State grouped by dropout")+
    geom_bar(mapping = aes(x = State,fill=Dropout))

# Gender
table(TRAIN_DATA$Gender,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("Gender grouped by dropout")+
    geom_bar(mapping = aes(x = Gender,fill=Dropout))

# Hispanic
table(TRAIN_DATA$Hispanic,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("Hispanic students grouped by dropout")+
    geom_bar(mapping = aes(x = Hispanic,fill=Dropout))

# AmericanIndian
table(TRAIN_DATA$AmericanIndian,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("AmericanIndian students grouped by dropout")+
    geom_bar(mapping = aes(x = AmericanIndian,fill=Dropout))


# Asian
table(TRAIN_DATA$Asian,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("Asian students grouped by dropout")+
    geom_bar(mapping = aes(x = Asian,fill=Dropout))

# Black
table(TRAIN_DATA$Black,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("Black students grouped by dropout")+
    geom_bar(mapping = aes(x = Black,fill=Dropout))

# NativeHawaiian
table(TRAIN_DATA$NativeHawaiian,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
  ggtitle("NativeHawaiian students grouped by dropout")+
  geom_bar(mapping = aes(x = NativeHawaiian,fill=Dropout))

# White
table(TRAIN_DATA$White,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("White students grouped by dropout")+
    geom_bar(mapping = aes(x = White,fill=Dropout))


# TwoOrMoreRace
table(TRAIN_DATA$TwoOrMoreRace,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("Students withTwoOrMoreRace grouped by dropout")+
    geom_bar(mapping = aes(x = TwoOrMoreRace,fill=Dropout))


# HSDip
table(TRAIN_DATA$HSDip,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
ggtitle("Students HSDip grouped by dropout")+
    geom_bar(mapping = aes(x = HSDip,fill=Dropout))


# HighDeg
table(TRAIN_DATA$HighDeg,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
  ggtitle('Students HighDeg grouoped by dropout')+
  geom_bar(mapping = aes(x = HighDeg,fill=Dropout))

# EngPlacement
table(TRAIN_DATA$EngPlacement,TRAIN_DATA$Dropout,exclude = NULL)
ggplot(data = TRAIN_DATA) +
  ggtitle('Students EngPlacement grouped by dropout')+
  geom_bar(mapping = aes(x = EngPlacement,fill=Dropout))
```


```{r}
# GatewayMathStatus
table(TRAIN_DATA$GatewayMathStatus,TRAIN_DATA$Dropout)
ggplot(data = TRAIN_DATA) +
ggtitle('Students GatewayMathStatus grouped by dropout')+
    geom_bar(mapping = aes(x = GatewayMathStatus,fill=Dropout))
```

Correlation matrix of the financial aid data to check for multicollinearity among the continuous independent variables (The correlation is expected to be less than 0.5 so as to facilitate regression with multicollinearity)

```{r}
# Load the GGally package
library(GGally)
# Create a scatter plot matrix
vars <- c("Total_loan", "Total_grant", "Total_WorkStudy", "Total_scholarship")
ggpairs(TRAIN_DATA[vars])

```

```{r,warning=FALSE}
# Load the GGally package
library(GGally)
# Create a scatter plot matrix
vars <- c("Adjusted.Gross.Income","Parent.Adjusted.Gross.Income","CumLoanAtEntry")
ggpairs(TRAIN_DATA[vars])


```


### Hypotheses Tests

Hypotheses tests to test the relation between individual variables and the dependent variable (Dropout)
- The Null hypothesis: These variables have no relationship with Dropout.
- The Alternative hypothesis: These variables have a relationshop with Dropout.
- Decision rule: We reject Null hypothesis if the P-value is less than 0.05 and conclude that the variables have a relationship with Dropout and that Dropout of students is dependent on these variables.

```{r}
# Test for association
# Null hypothesis: The dropout of students is not related to gender of a student
attach(TRAIN_DATA)
chisq.test(Dropout,Gender)

# Null hypothesis: The dropout of students is not related to Marital.Status of a student 
chisq.test(Marital.Status,Dropout)

# Null hypothesis: The dropout of students is not related to the housing of a student 
chisq.test(Housing,Dropout)

 #Null hypothesis: The dropout of students is not related to the Father.s.Highest.Grade.Level 
chisq.test(Father.s.Highest.Grade.Level,Dropout)

# Null hypothesis: The dropout of students is not related to the Mother.s.Highest.Grade.Level 
chisq.test(Mother.s.Highest.Grade.Level,Dropout)

# Null hypothesis: The dropout of students is not related to GatewayMathStatus of the student
chisq.test(GatewayEnglishStatus,Dropout)


```

NOTE: Most variables had a relationship with dropout except marital status with p-value: 0.09 (p-value>0.05) where we do not reject null hypothesis and conclude that there is no enough statistical evidence to support the claim that dropout of students is related to  mariatal status of students. 



### Imputation of Missing Values

Summarize and look for the count of NA's in Individual variables 
```{r}
summary(TRAIN_DATA)
```

List the columns with missing values

```{r}
colnames(TRAIN_DATA)[colSums(is.na(TRAIN_DATA)) > 0]

```


Looking at the summary statistics of the TRAIN data frame there are variables:(‘HSGPAWtd','FirstGen','TransferIntent','Campus',,'Major2') that have missing values close to 90% of the whole column (>11,000), these variables if imputed may introduce bias, hence they were dropped.

- Also drop other variables that are string/nominal in nature: (state, address1, zip, Birthyear, BirthMonth and city) which even if they are imputed they have too many levels hence would increase number predictors unnecessarily after ‘OneHot’ encoding of categorical variables is done later hence too much bias.

```{r,warning=FALSE}
library(tidyverse)

drop.cols <- c('HSGPAWtd', 'FirstGen','TransferIntent','Campus','Address1',              'Address2','Major2','State','Zip','BirthYear','BirthMonth','City')

TRAIN_DATA<-TRAIN_DATA %>% select(-drop.cols)
dim(TRAIN_DATA)

# which columns have missing data
colnames(TRAIN_DATA)[colSums(is.na(TRAIN_DATA)) > 0]

```


Impute categorical variables with mode (most common category level in the variable)

```{r}

val<-unique(TRAIN_DATA$Marital.Status[!is.na(TRAIN_DATA$Marital.Status)]) # Values in vec_miss
mode <- val[which.max(tabulate(match(TRAIN_DATA$Marital.Status, val)))] # Mode of vec_miss
TRAIN_DATA$Marital.Status[is.na(TRAIN_DATA$Marital.Status)]<-mode # Impute by mode

val<-unique(TRAIN_DATA$Father.s.Highest.Grade.Level[!is.na(TRAIN_DATA$Father.s.Highest.Grade.Level)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Father.s.Highest.Grade.Level, val)))] 
TRAIN_DATA$Father.s.Highest.Grade.Level[is.na(TRAIN_DATA$Father.s.Highest.Grade.Level)]<-mode 

val<-unique(TRAIN_DATA$Mother.s.Highest.Grade.Level[!is.na(TRAIN_DATA$Mother.s.Highest.Grade.Level)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Mother.s.Highest.Grade.Level, val)))] 
TRAIN_DATA$Mother.s.Highest.Grade.Level[is.na(TRAIN_DATA$Mother.s.Highest.Grade.Level)]<-mode 

val<-unique(TRAIN_DATA$Housing[!is.na(TRAIN_DATA$Housing)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Housing, val)))] 
TRAIN_DATA$Housing[is.na(TRAIN_DATA$Housing)]<-mode


val<-unique(TRAIN_DATA$EngPlacement[!is.na(TRAIN_DATA$EngPlacement)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$EngPlacement, val)))] 
TRAIN_DATA$EngPlacement[is.na(TRAIN_DATA$EngPlacement)]<-mode

val<-unique(TRAIN_DATA$MathPlacement[!is.na(TRAIN_DATA$MathPlacement)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$MathPlacement, val)))] 
TRAIN_DATA$MathPlacement[is.na(TRAIN_DATA$MathPlacement)]<-mode

val<-unique(TRAIN_DATA$CompleteDevEnglish[!is.na(TRAIN_DATA$MathPlacement)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$CompleteDevEnglish, val)))] 
TRAIN_DATA$CompleteDevEnglish[is.na(TRAIN_DATA$CompleteDevEnglish)]<-mode

val<-unique(TRAIN_DATA$CompleteDevMath[!is.na(TRAIN_DATA$CompleteDevMath)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$CompleteDevMath, val)))] 
TRAIN_DATA$CompleteDevMath[is.na(TRAIN_DATA$CompleteDevMath)]<-mode


val<-unique(TRAIN_DATA$Hispanic[!is.na(TRAIN_DATA$Hispanic)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Hispanic, val)))] 
TRAIN_DATA$Hispanic[is.na(TRAIN_DATA$Hispanic)]<-mode 

val<-unique(TRAIN_DATA$AmericanIndian[!is.na(TRAIN_DATA$AmericanIndian)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$AmericanIndian, val)))] 
TRAIN_DATA$AmericanIndian[is.na(TRAIN_DATA$AmericanIndian)]<-mode 

val<-unique(TRAIN_DATA$Asian[!is.na(TRAIN_DATA$Asian)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Asian, val)))] 
TRAIN_DATA$Asian[is.na(TRAIN_DATA$Asian)]<-mode 

val<-unique(TRAIN_DATA$Black[!is.na(TRAIN_DATA$Black)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Black, val)))] 
TRAIN_DATA$Black[is.na(TRAIN_DATA$Black)]<-mode 

val<-unique(TRAIN_DATA$NativeHawaiian[!is.na(TRAIN_DATA$NativeHawaiian)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$NativeHawaiian, val)))] 
TRAIN_DATA$NativeHawaiian[is.na(TRAIN_DATA$NativeHawaiian)]<-mode 

val<-unique(TRAIN_DATA$White[!is.na(TRAIN_DATA$White)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$White, val)))] 
TRAIN_DATA$White[is.na(TRAIN_DATA$White)]<-mode 

val<-unique(TRAIN_DATA$TwoOrMoreRace[!is.na(TRAIN_DATA$TwoOrMoreRace)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$TwoOrMoreRace, val)))] 
TRAIN_DATA$TwoOrMoreRace[is.na(TRAIN_DATA$TwoOrMoreRace)]<-mode 

val<-unique(TRAIN_DATA$HSDip[!is.na(TRAIN_DATA$HSDip)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$HSDip, val)))] 
TRAIN_DATA$HSDip[is.na(TRAIN_DATA$HSDip)]<-mode 

val<-unique(TRAIN_DATA$HSDipYr[!is.na(TRAIN_DATA$HSDipYr)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$HSDipYr, val)))] 
TRAIN_DATA$HSDipYr[is.na(TRAIN_DATA$HSDipYr)]<-mode 

#Check which columns have missing data to ensure the imputed columns are not there
colnames(TRAIN_DATA)[colSums(is.na(TRAIN_DATA)) > 0]

```



Imputing continuous variables

- First check for normal distribution in order to impute with mean or median if they are not normally distributed (bell-shaped histogram and density plot shows normality)

- Adjusted.Gross.Income
```{r,warning=FALSE}

#Density plot
library(ggpubr)
ggdensity(TRAIN_DATA$Adjusted.Gross.Income, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
#Histogram
hist(TRAIN_DATA$Adjusted.Gross.Income) #histogram
# QQplot
ggqqplot(TRAIN_DATA$Adjusted.Gross.Income) #qqplot

```

- Total_loan
```{r,warning=FALSE}

#Density plot
library(ggpubr)
ggdensity(TRAIN_DATA$Total_loan, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
#Histogram
hist(TRAIN_DATA$Total_loan) #histogram
# QQplot
ggqqplot(TRAIN_DATA$Total_loan) #qqplot

```

- Total_grant
```{r,warning=FALSE}

#Density plot
library(ggpubr)
ggdensity(TRAIN_DATA$Total_grant, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
#Histogram
hist(TRAIN_DATA$Total_grant) #histogram
# QQplot
ggqqplot(TRAIN_DATA$Total_grant) #qqplot


```

- Total_scholarship
```{r,warning=FALSE}

# Density plot
ggdensity(TRAIN_DATA$Total_scholarship, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
# Histogram
hist(TRAIN_DATA$Total_scholarship) #histogram
# QQplot
ggqqplot(TRAIN_DATA$Total_scholarship) #qqplot

```


- Total_WorkStudy
```{r,warning=FALSE}
# Density plot
ggdensity(TRAIN_DATA$Total_WorkStudy, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
# Histogram
hist(TRAIN_DATA$Total_WorkStudy) #histogram
# QQplot
ggqqplot(TRAIN_DATA$Total_WorkStudy) #qqplot


```

- HSGPAUnwtd
```{r,warning=FALSE}
# Density plot
ggdensity(TRAIN_DATA$HSGPAUnwtd, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
# Histogram
hist(TRAIN_DATA$HSGPAUnwtd) #histogram
# QQplot
ggqqplot(TRAIN_DATA$HSGPAUnwtd) #qqplot


```

- NumColCredAttemptTransfer
```{r}

# Density plot
ggdensity(TRAIN_DATA$NumColCredAttemptTransfer, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
# Histogram
hist(TRAIN_DATA$NumColCredAcceptTransfer) #histogram
# QQplot
ggqqplot(TRAIN_DATA$NumColCredAcceptTransfer) #qqplot

```


- CumLoanAtEntry
```{r}

# Density plot
ggdensity(TRAIN_DATA$CumLoanAtEntry, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
# Histogram
hist(TRAIN_DATA$CumLoanAtEntry) #histogram
# QQplot
ggqqplot(TRAIN_DATA$CumLoanAtEntry) #qqplot

```


- TermGPA
```{r}
# Density plot
ggdensity(TRAIN_DATA$TermGPA, 
          main = "Density plot of tooth length",
          xlab = "Tooth length")
# Histogram
hist(TRAIN_DATA$TermGPA) #histogram
# QQplot
ggqqplot(TRAIN_DATA$TermGPA) #qqplot

```




- NOTE: the continous variables did not display normal distribution properties, thus imputation will be done using median intead of mean

#### Impute continuous variables using median

```{r,warning=FALSE}

for(i in 1:nrow(TRAIN_DATA)) {
  TRAIN_DATA[i, ][is.na(TRAIN_DATA[i,])]<-median(as.numeric(TRAIN_DATA[i,]), na.rm = TRUE)
}

# Count any missing data
sum(is.na(TRAIN_DATA))

# which columns have missing data
colnames(TRAIN_DATA)[colSums(is.na(TRAIN_DATA)) > 0]

TRAIN_Imputed=TRAIN_DATA

```


## TEST Data Imputation


- Now lets clean and impute missing data in the TEST_DATA as well
- Looking at the dataframe there are variables that have missing values close to 90% of the whole column (>11,000), these variables if imputed may introduce bias, hence they are dropped

```{r,warning=FALSE}
library(tidyverse)

drop.cols <- c('HSGPAWtd', 'FirstGen','TransferIntent','Campus','Address1',              'Address2','Major2','State','Zip','BirthYear','BirthMonth','City')


TEST_DATA<-TEST_DATA %>% select(-drop.cols)
colnames(TEST_DATA)

```

Ensure that all missing values and empty values are captured

```{r,warning=FALSE}

# Convert empty spaces and (-1) to NULL in order to facilitate imputation later on
TEST_DATA[TEST_DATA=="-1"]<-NA
TEST_DATA[TEST_DATA==""]<-NA

# Check for missing columns
colnames(TEST_DATA)[colSums(is.na(TEST_DATA)) > 0]
```



```{r,warning=FALSE}
# Impute categorical variables using mode

val<-unique(TEST_DATA$Marital.Status[!is.na(TEST_DATA$Marital.Status)]) # Values in vec_miss
mode <- val[which.max(tabulate(match(TEST_DATA$Marital.Status, val)))] # Mode of vec_miss
TEST_DATA$Marital.Status[is.na(TEST_DATA$Marital.Status)]<-mode # Impute by mode


val<-unique(TEST_DATA$Father.s.Highest.Grade.Level[!is.na(TEST_DATA$Father.s.Highest.Grade.Level)])
mode<-val[which.max(tabulate(match(TEST_DATA$Father.s.Highest.Grade.Level, val)))] 
TEST_DATA$Father.s.Highest.Grade.Level[is.na(TEST_DATA$Father.s.Highest.Grade.Level)]<-mode 

val<-unique(TEST_DATA$Mother.s.Highest.Grade.Level[!is.na(TEST_DATA$Mother.s.Highest.Grade.Level)])
mode<-val[which.max(tabulate(match(TEST_DATA$Mother.s.Highest.Grade.Level, val)))] 
TEST_DATA$Mother.s.Highest.Grade.Level[is.na(TEST_DATA$Mother.s.Highest.Grade.Level)]<-mode 

val<-unique(TEST_DATA$Housing[!is.na(TEST_DATA$Housing)])
mode<-val[which.max(tabulate(match(TEST_DATA$Housing, val)))] 
TEST_DATA$Housing[is.na(TEST_DATA$Housing)]<-mode


val<-unique(TEST_DATA$EngPlacement[!is.na(TEST_DATA$EngPlacement)])
mode<-val[which.max(tabulate(match(TEST_DATA$EngPlacement, val)))] 
TEST_DATA$EngPlacement[is.na(TEST_DATA$EngPlacement)]<-mode


val<-unique(TEST_DATA$MathPlacement[!is.na(TEST_DATA$MathPlacement)])
mode<-val[which.max(tabulate(match(TEST_DATA$MathPlacement, val)))] 
TEST_DATA$MathPlacement[is.na(TEST_DATA$MathPlacement)]<-mode


val<-unique(TEST_DATA$CompleteDevEnglish[!is.na(TEST_DATA$MathPlacement)])
mode<-val[which.max(tabulate(match(TEST_DATA$CompleteDevEnglish, val)))] 
TEST_DATA$CompleteDevEnglish[is.na(TEST_DATA$CompleteDevEnglish)]<-mode


val<-unique(TEST_DATA$CompleteDevMath[!is.na(TEST_DATA$CompleteDevMath)])
mode<-val[which.max(tabulate(match(TEST_DATA$CompleteDevMath, val)))] 
TEST_DATA$CompleteDevMath[is.na(TEST_DATA$CompleteDevMath)]<-mode

val<-unique(TEST_DATA$Hispanic[!is.na(TEST_DATA$Hispanic)])
mode<-val[which.max(tabulate(match(TEST_DATA$Hispanic, val)))] 
TEST_DATA$Hispanic[is.na(TEST_DATA$Hispanic)]<-mode 

val<-unique(TEST_DATA$AmericanIndian[!is.na(TEST_DATA$AmericanIndian)])
mode<-val[which.max(tabulate(match(TEST_DATA$AmericanIndian, val)))] 
TEST_DATA$AmericanIndian[is.na(TEST_DATA$AmericanIndian)]<-mode 

val<-unique(TEST_DATA$Asian[!is.na(TEST_DATA$Asian)])
mode<-val[which.max(tabulate(match(TEST_DATA$Asian, val)))] 
TEST_DATA$Asian[is.na(TEST_DATA$Asian)]<-mode 

val<-unique(TEST_DATA$Black[!is.na(TEST_DATA$Black)])
mode<-val[which.max(tabulate(match(TEST_DATA$Black, val)))] 
TEST_DATA$Black[is.na(TEST_DATA$Black)]<-mode 

val<-unique(TEST_DATA$NativeHawaiian[!is.na(TEST_DATA$NativeHawaiian)])
mode<-val[which.max(tabulate(match(TEST_DATA$NativeHawaiian, val)))] 
TEST_DATA$NativeHawaiian[is.na(TEST_DATA$NativeHawaiian)]<-mode 

val<-unique(TEST_DATA$White[!is.na(TEST_DATA$White)])
mode<-val[which.max(tabulate(match(TEST_DATA$White, val)))] 
TEST_DATA$White[is.na(TEST_DATA$White)]<-mode 

val<-unique(TEST_DATA$TwoOrMoreRace[!is.na(TEST_DATA$TwoOrMoreRace)])
mode<-val[which.max(tabulate(match(TEST_DATA$TwoOrMoreRace, val)))] 
TEST_DATA$TwoOrMoreRace[is.na(TEST_DATA$TwoOrMoreRace)]<-mode 

val<-unique(TEST_DATA$HSDip[!is.na(TEST_DATA$HSDip)])
mode<-val[which.max(tabulate(match(TEST_DATA$HSDip, val)))] 
TEST_DATA$HSDip[is.na(TEST_DATA$HSDip)]<-mode 

val<-unique(TEST_DATA$HSDipYr[!is.na(TEST_DATA$HSDipYr)])
mode<-val[which.max(tabulate(match(TEST_DATA$HSDipYr, val)))] 
TEST_DATA$HSDipYr[is.na(TEST_DATA$HSDipYr)]<-mode 

#Check which columns have missing data to ensure the imputed columns are not there
colnames(TEST_DATA)[colSums(is.na(TEST_DATA)) > 0]
```



```{r,warning=FALSE}
# Impute using median the other numeric variables
for(i in 1:nrow(TEST_DATA)) {
  TEST_DATA[i, ][is.na(TEST_DATA[i,])]<-median(as.numeric(TEST_DATA[i,]), na.rm = TRUE)
}

# Ensure no missing columns left (we expect zero)
colnames(TEST_DATA)[colSums(is.na(TEST_DATA)) > 0]

TEST_Imputed=TEST_DATA

```


# FEATURE ENGINEERING

#### Implement feature selection using Boruta package 

```{r,warning=FALSE}
library(Boruta)

# Now is the time to implement and check the performance of boruta package. The syntax of boruta is almost similar to regression (lm) method.

set.seed(123)
boruta.train <- Boruta(Dropout~.-StudentID, data = TRAIN_Imputed, doTrace = 2)
print(boruta.train)
```


```{r,warning=FALSE}
# Now, we’ll plot the boruta variable importance chart.
plot(boruta.train, xlab = "", xaxt = "n")
 lz<-lapply(1:ncol(boruta.train$ImpHistory),function(i)
  boruta.train$ImpHistory[is.finite(boruta.train$ImpHistory[,i]),i])
 names(lz) <- colnames(boruta.train$ImpHistory)
 Labels <- sort(sapply(lz,median))
 axis(side = 1,las=2,labels = names(Labels),
       at = 1:ncol(boruta.train$ImpHistory), cex.axis = 0.7)

```


- Blue boxplots correspond to minimal, average and maximum Z score of a shadow attribute. Red, yellow and green boxplots represent Z scores of rejected, tentative and confirmed attributes respectively.
- Now is the time to take decision on tentative attributes.  The tentative attributes will be classified as confirmed or rejected by comparing the median Z score of the attributes with the median Z score of the best shadow attribute. Let’s do it.

```{r,warning=FALSE}

final.boruta <- TentativeRoughFix(boruta.train)
print(final.boruta)

```



We’ll create a data frame of the final result derived from Boruta.

```{r,warning=FALSE}
boruta.df <- attStats(final.boruta)
class(boruta.df)

print(boruta.df)
```

It’s time for results now. Let’s obtain the list of confirmed attributes

```{r,warning=FALSE}
features=getSelectedAttributes(final.boruta, withTentative = F) 
features #List all selected features

# Apply the features onto the TRAIN imputed data
TRAIN_Features=TRAIN_Imputed[,features]

# Attach the Dropout variable back to the TRAIN Features data frame
TRAIN_Features$Dropout=TRAIN_Imputed$Dropout
dim(TRAIN_Features)

# Also apply the feature selection on the TEST DATA
TEST_Features=TEST_Imputed[,features]

# Save the TRAIN and TEST features in csv files because we can load them later to avoid the time consuming process of feature engineering.

#write.csv(TRAIN_Features,"D:/Hamed/KAGGLE COMPETITION/FEATURES/clean_features/TRAIN_Features.csv")

#write.csv(TEST_Features,"D:/Hamed/KAGGLE COMPETITION/FEATURES/clean_features/TEST_Features.csv")


```

#### Let’s understand the parameters used in Boruta as follows:

- maxRuns: maximal number of random forest runs.
You can consider increasing this parameter if tentative attributes are left.Default is 100.
- doTrace: It refers to verbosity level. 0 means no tracing. 1 means reporting attribute decision as soon as it is cleared. 2 means all of 1 plus additionally reporting each iteration. Default is 0.
- holdHistory: The full history of importance runs is stored if set to TRUE
(Default). Gives a plot of Classifier run vs. Importance when the plotImpHistory function is called to run.




#### Data Standardization: 

- Derive Dummy variables out of categorical variables and normalization of continuous variables

```{r}

# Create Dummy varibales
library(dummies)

TRAIN_Features <- dummy.data.frame(TRAIN_Features, names = c("cohort_term","Marital.Status" , "Father.s.Highest.Grade.Level","Mother.s.Highest.Grade.Level",
                  "Housing","Cohort") , sep = ".")
dim(TRAIN_Features)

```

#### Standardization of continuous variables

TRAIN DATA transformation

```{r,warning=FALSE}

library(caret)
# calculate the pre-process parameters from the dataset
preprocessParams <- preProcess(TRAIN_Features[,1:52], method=c("center", "scale"))
# summarize transform parameters
print(preprocessParams)
# transform the dataset using the parameters
transformed_train <- predict(preprocessParams, TRAIN_Features[,1:52]) #exclude Dropout variable
# summarize the transformed dataset
summary(transformed_train)
dim(transformed_train)
transformed_train$Dropout=TRAIN_Features$Dropout #re-include Dropout variable


# save the claen and transformed features into a local folder for future use
#write.csv(transformed_train,"D:/Hamed/KAGGLE COMPETITION/FEATURES/clean_features/transformed_train.csv")

```

TEST DATA transformation

```{r,warning=FALSE}

vars=c("cohort_term","Marital.Status" ,"Father.s.Highest.Grade.Level",
       "Mother.s.Highest.Grade.Level","Housing","Cohort")
TEST_Features[,vars] <- lapply(TEST_Features[,vars] , factor)
TEST_Features<-dummy.data.frame(TEST_Features,names = vars,sep=".")
dim(TEST_Features)

# Also standardize the test features
library(caret)
# calculate the pre-process parameters from the dataset
preprocessParams <- preProcess(TEST_Features[,1:52], method=c("center", "scale"))
# summarize transform parameters
print(preprocessParams)
# transform the dataset using the parameters
transformed_test <- predict(preprocessParams, TEST_Features[,1:52])
# summarize the transformed dataset
summary(transformed_test)
dim(transformed_test)



# save the claen and transformed features into a local folder for future use
#write.csv(transformed_test,"D:/Hamed/KAGGLE COMPETITION/FEATURES/clean_features/transformed_test.csv")

```


