summary(TRAIN_DATA)
set.seed(123)
boruta.train <- Boruta(Dropout~.-StudentID, data = TRAIN_DATA, doTrace = 2)
TRAIN_DATA$Marital.Status[is.na(TRAIN_DATA$Marital.Status)]=mode(TRAIN_DATA$Marital.Status,na.rm=TRUE)
vec_miss <- TRAIN_DATA[,c("Marital.Status","Father.s.Highest.Grade.Level",
"Mother.s.Highest.Grade.Level","Housing",
"Address1","State","City","Zip","BirthYear",
"Hispanic","AmericanIndian","Asian","Black","NativeHawaiian",
"White","TwoOrMoreRace","HSDip")] # Replicate vector
table(vec_miss) # Count of each category
sum(is.na(vec_miss))
val <- unique(TRAIN_DATA[!is.na(TRAIN_DATA)]) # Values in vec_miss
mode <- val[which.max(tabulate(match(TRAIN_DATA, val)))] # Mode of vec_miss
mode
vec_imp <- vec_miss # Replicate vec_miss
vec_imp[is.na(vec_imp)] <- mode   # Impute by mode
val
val<-unique(TRAIN_DATA$Marital.Status[!is.na(TRAIN_DATA$Marital.Status)]) # Values in vec_miss
val
mode <- val[which.max(tabulate(match(TRAIN_DATA$Marital.Status, val)))] # Mode of vec_miss
mode
TRAIN_DATA$Marital.Status[is.na(TRAIN_DATA$Marital.Status)] <- mode   # Impute by mode
View(TRAIN_DATA)
# FINANCIAL AID DATA
financial_aid<-read.csv("financial_aid.csv",header = T)
#Combine by summing the data over the years
library(tidyverse)
attach(financial_aid)
financial_aid=financial_aid %>%
mutate(Total_loan = select(.,c(X2012.Loan,X2013.Loan,X2014.Loan,
X2015.Loan,X2016.Loan,X2017.Loan)) %>%
rowSums(na.rm = TRUE))
financial_aid<-financial_aid%>%
mutate(Total_grant=select(.,c(X2012.Grant,X2013.Grant,X2014.Grant,
X2015.Grant,X2016.Grant,X2017.Grant))%>%
rowSums(na.rm = TRUE))
financial_aid<-financial_aid%>%
mutate(Total_scholarship=select(.,c(X2012.Scholarship,X2013.Scholarship,X2014.Scholarship,
X2015.Scholarship,X2016.Scholarship,X2017.Scholarship))%>%
rowSums(na.rm = TRUE))
financial_aid<-financial_aid%>%
mutate(Total_WorkStudy=select(.,c(X2012.Work.Study,X2013.Work.Study,
X2014.Work.Study,X2015.Work.Study,X2016.Work.Study,X2017.Work.Study))%>%
rowSums(na.rm = TRUE))
colnames(financial_aid)
financial_aid<-financial_aid[,-c(9:32)]
colnames(financial_aid)
# Load the train labels and the TestIDs
train_labels=read.csv("DropoutTrainLabels.csv",header = T)
testIDs=read.csv("TestIDs.csv",header = T)
# JOIN the train labels and the financial aid data
library(dplyr)
financial_aid_train=left_join(train_labels,financial_aid,by="StudentID")
colnames(financial_aid_train)
# JOIN the test IDs and the financial aid data
financial_aid_test=left_join(testIDs,financial_aid,by="StudentID")
colnames(financial_aid_test)
#check for duplicated StudentID (TRUE=No duplicates, FALSE=duplicates present)
length(unique(financial_aid_train$StudentID)) == nrow(financial_aid_train)
# STATIC DATA
#STATIC data merged through ETL
#load all files and merge them
myETL=function(mypath){
filenames = list.files(path=mypath, full.names=TRUE)
file_load = function(x){read.csv(file=x,header=T)}
datalist = lapply(filenames, file_load)
data2 = do.call(rbind, lapply(datalist, as.data.frame))
return(data2)
}
# call the function
mergedStatic<-myETL("D:/KAZI/UPWORK/KAGGLE COMPETITION/Student Retention Challenge Data/Student Static Data")
#check for duplicated StudentID (TRUE=No duplicates, FALSE=duplicates present)
length(unique(mergedStatic$StudentID)) == nrow(mergedStatic)
# JOIN the train labels and the static data
library(dplyr)
static_train=left_join(train_labels,mergedStatic,by="StudentID")
# JOIN the test IDs and the static data
static_test=left_join(testIDs,mergedStatic,by="StudentID")
# PROGRESS DATA
#Progress data merged through ETL
#load all files and merge them
myETL=function(mypath){
filenames = list.files(path=mypath, full.names=TRUE)
file_load = function(x){read.csv(file=x,header=T)}
datalist = lapply(filenames, file_load)
data2 = do.call(rbind, lapply(datalist, as.data.frame))
return(data2)
}
# call the function
mergedProgress<-myETL("D:/KAZI/UPWORK/KAGGLE COMPETITION/Student Retention Challenge Data/Student Progress Data")
colnames(mergedProgress)
#check for duplicated StudentID (TRUE=No duplicates, FALSE=duplicates present)
length(unique(mergedProgress$StudentID)) == nrow(mergedProgress)
library(plyr)
# summarise the data to get rid of duplicated StudentID
prog1=ddply(mergedProgress,.(StudentID),summarize,
CompleteDevMath=mean(CompleteDevMath),CompleteDevEnglish=mean(CompleteDevEnglish),
Major1=mean(Major1),Major2=mean(Major2),Complete1=mean(Complete1),
Complete2=mean(Complete2),CompleteCIP1=mean(CompleteCIP1),
CompleteCIP2=mean(CompleteCIP2),TransferIntent=mean(TransferIntent),
DegreeTypeSought=mean(DegreeTypeSought),TermGPA=mean(CumGPA),
CumGPA=mean(CumGPA),number=length(StudentID))
dim(prog1)
prog1<-prog1[,-14]
dim(prog1)
colnames(prog1)
# JOIN the train labels and the progress data
library(dplyr)
progress_train=left_join(train_labels,prog1,by="StudentID")
# JOIN the test IDs and the progress data
progress_test=left_join(testIDs,prog1,by="StudentID")
dim(progress_train)
# Check to ensure the datasets are of the same sizes before merging them
dim(financial_aid_train)
dim(financial_aid_test)
dim(static_train)
dim(static_test)
dim(progress_train)
dim(progress_test)
# TRAINING DATASET
library(dplyr)
join1<-inner_join(financial_aid_train,static_train,by="StudentID")
TRAIN_DATA=inner_join(join1,progress_train,by="StudentID")
dim(TRAIN_DATA)
colnames(TRAIN_DATA)
# TESTING DATASET
join2<-inner_join(financial_aid_test,static_test,by="StudentID")
TEST_DATA<-inner_join(join2,progress_test,by="StudentID")
dim(TEST_DATA)
colnames(TEST_DATA)
# Clean the train data by removing extra dropout variables (Dropout.y,Dropout)
TRAIN_DATA<-select(TRAIN_DATA,-c("Dropout.y"))
TRAIN_DATA<-select(TRAIN_DATA,-c("Dropout"))
# Rename the droput.x to just dropout for consistency
library(dplyr)
colnames(TRAIN_DATA)[colnames(TRAIN_DATA)=="Dropout.x"] <- "Dropout"
colnames(TRAIN_DATA)
dim(TRAIN_DATA)
dim(TEST_DATA)
# convert empty spaces and (-1) to NULL in order to facilitate imputation later on
str(TRAIN_DATA)
TRAIN_DATA[TRAIN_DATA=="-1"]<-NA
TRAIN_DATA[TRAIN_DATA==""]<-NA
# convert the theorically categorical variables to  factors
colnames(TRAIN_DATA)
names=c('DegreeTypeSought','TransferIntent','GatewayEnglishStatus',
'GatewayMathStatus','EngPlacement','MathPlacement','HighDeg',
'EnrollmentStatus','HSDip','Gender','Campus','CohortTerm',
'cohort_term','Dropout')
TRAIN_DATA[,names]<-lapply(TRAIN_DATA[,names] , factor)
str(TRAIN_DATA)
colnames(TRAIN_DATA)
summary(TRAIN_DATA)
# DROP EMPTY COLUMNS
drop.cols <- c('HSGPAWtd', 'FirstGen','TransferIntent','Campus',
'Address2','Major2')
TRAIN_DATA<-TRAIN_DATA %>% select(-drop.cols)
dim(TRAIN_DATA)
str(TRAIN_DATA)
TEST_DATA<-TEST_DATA %>% select(-drop.cols)
dim(TEST_DATA)
str(TEST_DATA)
ggplot(data = TRAIN_DATA) +
geom_bar(mapping = aes(x = Dropout,color=Dropout))
ggplot(data = TRAIN_DATA) +
geom_bar(mapping = aes(x = Marital.Status,color=Dropout))
ggplot(data = TRAIN_DATA) +
geom_bar(mapping = aes(x = Marital.Status,colour=Dropout))
ggplot(data = TRAIN_DATA) +
geom_bar(mapping = aes(x = Marital.Status,colour=Gender))
ggplot(data = TRAIN_DATA) +
geom_bar(mapping = aes(x = Marital.Status,fill=Gender))
dim(TEST_DATA)
dim(TRAIN_DATA)
for(i in 1:nrow(TRAIN_DATA)) {
TRAIN_DATA[i, ][is.na(TRAIN_DATA[i,])]<-median(as.numeric(TRAIN_DATA[i,]), na.rm = TRUE)
}
colnames(TRAIN_DATA)[colSums(is.na(TRAIN_DATA))>0]
val<-unique(TRAIN_DATA$Marital.Status[!is.na(TRAIN_DATA$Marital.Status)]) # Values in vec_miss
mode <- val[which.max(tabulate(match(TRAIN_DATA$Marital.Status, val)))] # Mode of vec_miss
TRAIN_DATA$Marital.Status[is.na(TRAIN_DATA$Marital.Status)]<-mode # Impute by mode
val<-unique(TRAIN_DATA$Father.s.Highest.Grade.Level[!is.na(TRAIN_DATA$Father.s.Highest.Grade.Level)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Father.s.Highest.Grade.Level, val)))]
TRAIN_DATA$Father.s.Highest.Grade.Level[is.na(TRAIN_DATA$Father.s.Highest.Grade.Level)]<-mode
val<-unique(TRAIN_DATA$Mother.s.Highest.Grade.Level[!is.na(TRAIN_DATA$Mother.s.Highest.Grade.Level)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Mother.s.Highest.Grade.Level, val)))]
TRAIN_DATA$Mother.s.Highest.Grade.Level[is.na(TRAIN_DATA$Mother.s.Highest.Grade.Level)]<-mode
val<-unique(TRAIN_DATA$Housing[!is.na(TRAIN_DATA$Housing)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Housing, val)))]
TRAIN_DATA$Housing[is.na(TRAIN_DATA$Housing)]<-mode
val<-unique(TRAIN_DATA$EngPlacement[!is.na(TRAIN_DATA$EngPlacement)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$EngPlacement, val)))]
TRAIN_DATA$EngPlacement[is.na(TRAIN_DATA$EngPlacement)]<-mode
val<-unique(TRAIN_DATA$MathPlacement[!is.na(TRAIN_DATA$MathPlacement)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$MathPlacement, val)))]
TRAIN_DATA$MathPlacement[is.na(TRAIN_DATA$MathPlacement)]<-mode
val<-unique(TRAIN_DATA$CompleteDevEnglish[!is.na(TRAIN_DATA$MathPlacement)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$CompleteDevEnglish, val)))]
TRAIN_DATA$CompleteDevEnglish[is.na(TRAIN_DATA$CompleteDevEnglish)]<-mode
val<-unique(TRAIN_DATA$CompleteDevMath[!is.na(TRAIN_DATA$CompleteDevMath)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$CompleteDevMath, val)))]
TRAIN_DATA$CompleteDevMath[is.na(TRAIN_DATA$CompleteDevMath)]<-mode
val<-unique(TRAIN_DATA$Address1[!is.na(TRAIN_DATA$Address1)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Address1, val)))]
TRAIN_DATA$Address1[is.na(TRAIN_DATA$Address1)]<-mode
val<-unique(TRAIN_DATA$State[!is.na(TRAIN_DATA$State)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$State, val)))]
TRAIN_DATA$State[is.na(TRAIN_DATA$State)]<-mode
val<-unique(TRAIN_DATA$City[!is.na(TRAIN_DATA$City)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$City, val)))]
TRAIN_DATA$City[is.na(TRAIN_DATA$City)]<-mode
val<-unique(TRAIN_DATA$Zip[!is.na(TRAIN_DATA$Zip)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Zip, val)))]
TRAIN_DATA$Zip[is.na(TRAIN_DATA$Zip)]<-mode
val<-unique(TRAIN_DATA$BirthYear[!is.na(TRAIN_DATA$BirthYear)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$BirthYear, val)))]
TRAIN_DATA$BirthYear[is.na(TRAIN_DATA$BirthYear)]<-mode
val<-unique(TRAIN_DATA$Hispanic[!is.na(TRAIN_DATA$Hispanic)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Hispanic, val)))]
TRAIN_DATA$Hispanic[is.na(TRAIN_DATA$Hispanic)]<-mode
val<-unique(TRAIN_DATA$AmericanIndian[!is.na(TRAIN_DATA$AmericanIndian)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$AmericanIndian, val)))]
TRAIN_DATA$AmericanIndian[is.na(TRAIN_DATA$AmericanIndian)]<-mode
val<-unique(TRAIN_DATA$Asian[!is.na(TRAIN_DATA$Asian)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Asian, val)))]
TRAIN_DATA$Asian[is.na(TRAIN_DATA$Asian)]<-mode
val<-unique(TRAIN_DATA$Black[!is.na(TRAIN_DATA$Black)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$Black, val)))]
TRAIN_DATA$Black[is.na(TRAIN_DATA$Black)]<-mode
val<-unique(TRAIN_DATA$NativeHawaiian[!is.na(TRAIN_DATA$NativeHawaiian)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$NativeHawaiian, val)))]
TRAIN_DATA$NativeHawaiian[is.na(TRAIN_DATA$NativeHawaiian)]<-mode
val<-unique(TRAIN_DATA$White[!is.na(TRAIN_DATA$White)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$White, val)))]
TRAIN_DATA$White[is.na(TRAIN_DATA$White)]<-mode
val<-unique(TRAIN_DATA$TwoOrMoreRace[!is.na(TRAIN_DATA$TwoOrMoreRace)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$TwoOrMoreRace, val)))]
TRAIN_DATA$TwoOrMoreRace[is.na(TRAIN_DATA$TwoOrMoreRace)]<-mode
val<-unique(TRAIN_DATA$HSDip[!is.na(TRAIN_DATA$HSDip)])
mode<-val[which.max(tabulate(match(TRAIN_DATA$HSDip, val)))]
TRAIN_DATA$HSDip[is.na(TRAIN_DATA$HSDip)]<-mode
# which columns have missing data
colnames(TRAIN_DATA)[colSums(is.na(TRAIN_DATA)) > 0]
library(Boruta)
set.seed(123)
boruta.train <- Boruta(Dropout~.-StudentID, data = TRAIN_DATA, doTrace = 2)
print(boruta.train)
# Now, we’ll plot the boruta variable importance chart.
plot(boruta.train, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(boruta.train$ImpHistory),function(i)
boruta.train$ImpHistory[is.finite(boruta.train$ImpHistory[,i]),i])
names(lz) <- colnames(boruta.train$ImpHistory)
Labels <- sort(sapply(lz,median))
axis(side = 1,las=2,labels = names(Labels),
at = 1:ncol(boruta.train$ImpHistory), cex.axis = 0.7)
# Blue boxplots correspond to minimal, average and maximum Z score of a shadow attribute. Red, yellow and green boxplots represent Z scores of rejected, tentative and confirmed attributes respectively.
# Now is the time to take decision on tentative attributes.  The tentative attributes will be classified as confirmed or rejected by comparing the median Z score of the attributes with the median Z score of the best shadow attribute. Let’s do it.
final.boruta <- TentativeRoughFix(boruta.train)
print(final.boruta)
# It’s time for results now. Let’s obtain the list of confirmed attributes
getSelectedAttributes(final.boruta, withTentative = F)
# We’ll create a data frame of the final result derived from Boruta.
boruta.df <- attStats(final.boruta)
class(boruta.df)
print(boruta.df)
library(caret)
library(randomForest)
set.seed(123)
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
rfe.train <- rfe(traindata[,2:12], traindata[,13], sizes=1:12, rfeControl=control)
rfe.train <- rfe(traindata[,2:12], traindata[,13], sizes=1:12, rfeControl=control)
rfe.train <- rfe(TRAIN_DATA[,2:12], TRAIN_DATA[,13], sizes=1:12, rfeControl=control)
rfe.train
plot(rfe.train, type=c("g", "o"), cex = 1.0, col = 1:11)
# Let’s extract the chosen features. I am confident it would result in Credit History.
predictors(rfe.train)
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
rfe.train <- rfe(TRAIN_DATA[,2:12], TRAIN_DATA[,13], sizes=1:12, rfeControl=control)
rfe.train
View(boruta.df)
dim(boruta.df)
colnames(boruta.df)
dim(TRAIN_DATA)
dim(TEST_DATA)
table(boruta.df$decision)
#Load packages
library(tidyverse)
library(rpart)
library(dplyr)
# First split the dataset
set.seed(123)
# First split the dataset
set.seed(123)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(boruta.df))
train_ind <- sample(seq_len(nrow(boruta.df)), size = smp_size)
train.cancer <- boruta.df[train_ind, ]
test.cancer <- boruta.df[-train_ind, ]
dim(train.cancer)
dim(test.cancer)
dim(boruta.df)
boruta.df[boruta.df$decision=='Confirmed']
boruta.df[,boruta.df$decision=='Confirmed']
boruta.df[boruta.df$decision=='Confirmed']
boruta.df[boruta.df$decision='Confirmed']
boruta.df$decision='Confirmed'
View(boruta.df)
dim(boruta.df)
# It’s time for results now. Let’s obtain the list of confirmed attributes
getSelectedAttributes(final.boruta, withTentative = F)
TRAIN_DATA[,features]
# It’s time for results now. Let’s obtain the list of confirmed attributes
features<-getSelectedAttributes(final.boruta, withTentative = F)
TRAIN_DATA[,features]
X_train=TRAIN_DATA[,features]
dim(X_train)
View(X_train)
str(X_train)
y_train=TRAIN_DATA[dropout]
y_train=TRAIN_DATA$dropout
TRAIN_SET=TRAIN_DATA[,features]
TRAIN_SET$Dropout=TRAIN_DATA$Dropout
View(TRAIN_SET)
table(TRAIN_DATA$Dropout)
#Load packages
library(tidyverse)
library(rpart)
library(dplyr)
set.seed(123)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(TRAIN_SET))
train_ind <- sample(seq_len(nrow(TRAIN_SET)), size = smp_size)
train.set <- TRAINING_SET[train_ind, ]
validation.set <- TRAINING_SET[-train_ind, ]
set.seed(123)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(TRAIN_SET))
train_ind <- sample(seq_len(nrow(TRAIN_SET)), size = smp_size)
train.set <- TRAIN_SET[train_ind, ]
validation.set <- TRAIN_SET[-train_ind, ]
model_tree<-train(Dropout~.,data=train.set, method = "rpart",
trControl = trainControl("cv", number = 5),tuneLength = 3)
setwd("~/")
financial_aid<-read.csv("financial_aid.csv",header = T)
getwd()
TRAIN_DATA=read.csv("TRAIN.csv",header = T)
dim(TRAIN_DATA)
colnames(TRAIN_DATA)
TRAIN_DATA[,features]
# Stochastic Gradient Boosting GBM model
set.seed(seed)
set.seed(7)
fit.c50 <- train(Dropout~., data=train.set, method = "C5.0", metric="Accuracy", trControl=trainControl(method="repeatedcv", number=10, repeats=3))
# Stochastic Gradient Boosting GBM model
library(caret)
set.seed(7)
fit.c50 <- train(Dropout~., data=train.set, method = "C5.0", metric="Accuracy", trControl=trainControl(method="repeatedcv", number=10, repeats=3))
fit.gbm <- train(Dropout~., data=train.set, method="gbm", metric="Accuracy",
trControl=trainControl(method="repeatedcv", number=10,
repeats=3), verbose=FALSE)
# Stochastic Gradient Boosting GBM model
library(caret)
set.seed(123)
fit.c50<-train(Dropout~., data=train.set, method = "C5.0", metric="Accuracy",
trControl=trainControl(method="repeatedcv", number=10, repeats=3))
models <- caretList(Dropout ~. ,data=train.set,trControl=control
,methodList=algorithmList)
##Try a stacking ensemble with at least two different models.set the response variable to factor
library(mlbench)
library(caret)
library(caretEnsemble)
TRAIN_Features$Dropout=as.factor(TRAIN_Features$Dropout)
class(Dropout)
# SPlit the datasets
set.seed(123)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(TRAIN_Features))
train_ind <- sample(seq_len(nrow(TRAIN_Features)), size = smp_size)
# Example of Stacking algorithms
# create submodels
control<-trainControl(method="repeatedcv", number=10, repeats=3,
savePredictions=TRUE)
algorithmList <- c('rpart','glm', 'knn', 'svmRadial')
class(Dropout)
models <- caretList(Dropout ~. ,data=train.set,trControl=control
,methodList=algorithmList)
setwd("D:/KAZI/UPWORK/KAGGLE COMPETITION/FEATURES/clean_features")
transformed_train=read.csv("transformed_train.csv",header = T)
transformed_test=read.csv("transformed_test.csv",header = T)
transformed_train$Dropout=as.factor(transformed_train$Dropout)
# Load required packages
library(class)
library(caret)
library(rpart)
library(dplyr)
library(gbm)
# Split the transformed_train dataset into training and validation datasets
set.seed(123)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(transformed_train))
train_ind <- sample(seq_len(nrow(transformed_train)), size = smp_size)
train.set <- transformed_train[train_ind, ]
validation.set <- transformed_train[-train_ind, ]
# Stochastic Gradient Boosting GBM model
library(caret)
set.seed(123)
fit.c50<-train(Dropout~., data=train.set, method = "C5.0", metric="Accuracy",
trControl=trainControl(method="repeatedcv", number=10, repeats=3))
fit.c50
# Evaluation of model accuracy
predict_c50<-predict.train(object=fit.c50,validation.set,type="raw")
confusionMatrix(predict_c50,validation.set$Dropout)
# Predict new data
pred.c50<-predict.train(object=fit.c50,transformed_test,type="raw")
pred.c50=as.data.frame(pred.c50)
# save the prediction
write.csv(pred.c50,"D:/KAZI/UPWORK/KAGGLE COMPETITION/FEATURES/my_new_submission/submission_c50.csv")
library(gbm)
set.seed(seed)
set.seed(123)
fit.gbm <- train(Dropout~., data=train.set, method="gbm", metric="Accuracy",
trControl=trainControl(method="repeatedcv", number=10,
repeats=3), verbose=FALSE)
fit.gbm
# Evaluation of model accuracy
predict_gbm<-predict.train(object=fit.gbm,validation.set,type="raw")
confusionMatrix(predict_gbm,validation.set$Dropout)
# Predict new data
pred.gbm<-predict.train(object=fit.gbm,transformed_test,type="raw")
pred.gbm=as.data.frame(pred.gbm)
# save the prediction
write.csv(pred.gbm,"D:/KAZI/UPWORK/KAGGLE COMPETITION/FEATURES/my_new_submission/submission_gbm.csv")
transformed_train=read.csv("transformed_train.csv",header = T)
transformed_test=read.csv("transformed_test.csv",header = T)
transformed_train$Dropout=as.factor(transformed_train$Dropout)
# Load required packages
library(class)
library(caret)
library(rpart)
library(dplyr)
# Split the transformed_train dataset into training and validation datasets
set.seed(123)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(transformed_train))
train_ind <- sample(seq_len(nrow(transformed_train)), size = smp_size)
train.set <- transformed_train[train_ind, ]
validation.set <- transformed_train[-train_ind, ]
transformed_train=read.csv("transformed_train.csv",header = T)
transformed_test=read.csv("transformed_test.csv",header = T)
transformed_train$Dropout=as.factor(transformed_train$Dropout)
# Load required packages
library(class)
library(caret)
library(rpart)
library(dplyr)
# Split the transformed_train dataset into training and validation datasets
set.seed(123)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(transformed_train))
train_ind <- sample(seq_len(nrow(transformed_train)), size = smp_size)
train.set <- transformed_train[train_ind, ]
validation.set <- transformed_train[-train_ind, ]
dim(train.set)
colnames(train.set)
transformed_train=read.csv("transformed_train.csv",header = T)
transformed_test=read.csv("transformed_test.csv",header = T)
transformed_train$Dropout=as.factor(transformed_train$Dropout)
# Load required packages
library(class)
library(caret)
library(rpart)
library(dplyr)
# Split the transformed_train dataset into training and validation datasets
set.seed(123)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(transformed_train))
train_ind <- sample(seq_len(nrow(transformed_train)), size = smp_size)
train.set <- transformed_train[train_ind, ]
validation.set <- transformed_train[-train_ind, ]
dim(train.set)
colnames(train.set)
library(caret)
set.seed(7)
fit.c50 <- train(Dropout~., data=train.set, method = "C5.0", metric="Accuracy", trControl=trainControl(method="repeatedcv", number=10, repeats=3))
fit.c50
# Evaluation of model accuracy
predict_c50<-predict.train(object=fit.c50,validation.set,type="raw")
confusionMatrix(predict_c50,validation.set$Dropout)
# Predict new data
pred.c50<-predict.train(object=fit.c50,transformed_test,type="raw")
pred.c50=as.data.frame(pred.c50)
head(pred.c50)
# save the prediction
#write.csv(pred.c50,"D:/KAZI/UPWORK/KAGGLE COMPETITION/FEATURES/my_new_submission/submission_c50.csv")
# Stochastic Gradient Boosting GBM model
set.seed(seed)
# Stochastic Gradient Boosting GBM model
set.seed(123)
fit.gbm <- train(Dropout~., data=train.set, method="gbm", metric="Accuracy", trControl=trainControl(method="repeatedcv", number=10, repeats=3), verbose=FALSE)
fit.gbm
# Predict new data
pred.gbm<-predict.train(object=fit.gbm,transformed_test,type="raw")
# Evaluation of model accuracy
predict_gbm<-predict.train(object=fit.gbm,validation.set,type="raw")
confusionMatrix(predict_gbm,validation.set$Dropout)
# Predict new data
pred.gbm<-predict.train(object=fit.gbm,transformed_test,type="raw")
pred.gbm=as.data.frame(pred.gbm)
head(pred.gbm)
# save the prediction
#write.csv(pred.gbm,"D:/KAZI/UPWORK/KAGGLE COMPETITION/FEATURES/my_new_submission/submission_gbm.csv")
boosting_results <- resamples(list(c5.0=fit.c50, gbm=fit.gbm))
